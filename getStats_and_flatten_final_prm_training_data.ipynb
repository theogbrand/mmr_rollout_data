{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ace7f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '000ac3e5-5a8b-4647-ab02-4932aa75b07a', 'image_url': '/data/users/brandon/ob1-projects/InternVL/internvl_chat/rollout_generation/preprocessed_prompts/preprocessing_scripts/VQAv2/subset_images/COCO_train2014_000000519929.jpg', 'conversations': [{'from': 'system', 'value': \"You are a Visual Reasoning Teacher. Given a visual reasoning question with provided images and a student's solution, evaluate the visual interpretation accuracy, logical consistency of the current step, and whether it will lead to the correct final solution.\"}, {'from': 'human', 'value': '### Question:\\nWhat is the sequence of numbers in the upper right corner? Answer the question using a single word or phrase.\\n\\n### Solution Process:\\n[Visual Elements]\\n<step_1>\\nThe image depicts a person playing a set of electronic drum pads, holding two drumsticks.\\n</step_1>'}, {'from': 'gpt', 'value': '+'}, {'from': 'human', 'value': '<step_2>\\nThere are four circular drum pads visible on the drum kit, each outlined in a different color (yellow, blue, green, and red).\\n</step_2>'}, {'from': 'gpt', 'value': '+'}, {'from': 'human', 'value': '<step_3>\\nIn the upper right corner of the image, there is no visible sequence of numbers present; this area is mostly dark and does not contain any text or numeric sequence.\\n</step_3>'}, {'from': 'gpt', 'value': '+'}, {'from': 'human', 'value': '[Reasoning]\\n<step_1>\\nThe question asks for the sequence of numbers in the upper right corner.\\n</step_1>'}, {'from': 'gpt', 'value': '+'}, {'from': 'human', 'value': '<step_2>\\nA thorough visual scan of the upper right corner reveals no numbers or numeric strings present in that area.\\n</step_2>'}, {'from': 'gpt', 'value': '+'}, {'from': 'human', 'value': '<step_3>\\nAs there are no numbers visible, the answer should reflect the absence of such a sequence.\\n</step_3>'}, {'from': 'gpt', 'value': '+'}], 'first_incorrect_step': None, 'steps_with_score': [{'step': 'The image depicts a person playing a set of electronic drum pads, holding two drumsticks.', 'score': 0.0, 'num_mc_correct': 0, 'num_mc_total': 16}, {'step': 'There are four circular drum pads visible on the drum kit, each outlined in a different color (yellow, blue, green, and red).', 'score': 0.0, 'num_mc_correct': 0, 'num_mc_total': 16}, {'step': 'In the upper right corner of the image, there is no visible sequence of numbers present; this area is mostly dark and does not contain any text or numeric sequence.', 'score': 0.0625, 'num_mc_correct': 1, 'num_mc_total': 16}, {'step': 'The question asks for the sequence of numbers in the upper right corner.', 'score': 0.0, 'num_mc_correct': 0, 'num_mc_total': 16}, {'step': 'A thorough visual scan of the upper right corner reveals no numbers or numeric strings present in that area.', 'score': 0.0, 'num_mc_correct': 0, 'num_mc_total': 16}, {'step': 'As there are no numbers visible, the answer should reflect the absence of such a sequence.', 'score': 0.0, 'num_mc_correct': 0, 'num_mc_total': 16}], 'consensus_filtering_algo_label': 'o4-mini_correct_and_MC_disagrees', 'verifier_identified_first_incorrect_step_solution': '[Visual Elements]\\n<analysis_1>\\nThe description “a person playing a set of electronic drum pads, holding two drumsticks” accurately matches the image, which shows an individual seated with drumsticks poised over circular pads.\\n</analysis_1>\\n<analysis_2>\\nThe image indeed contains four circular drum pads, each outlined in a distinct color (yellow, blue, green, red), consistent with common electronic drum controllers. This observation is correct.\\n</analysis_2>\\n<analysis_3>\\nA close inspection of the upper right corner reveals only darkness and part of the person’s head; there is no visible text or sequence of numbers. The claim of “no visible sequence of numbers” is accurate.\\n</analysis_3>\\n\\n[Reasoning]\\n<analysis_1>\\nThe solution correctly identifies that the question focuses on locating a numeric sequence in the upper right corner of the image.\\n</analysis_1>\\n<analysis_2>\\nThe reasoning “a thorough visual scan … reveals no numbers” is supported by the image content, which indeed contains no textual or numeric elements in that region.\\n</analysis_2>\\n<analysis_3>\\nConcluding that the answer should reflect the absence of numbers follows logically from the verified observation that no sequence is present.\\n</analysis_3>\\n\\n<conclusion>\\nCorrect\\n</conclusion>'}\n",
      "['id', 'image_url', 'conversations', 'first_incorrect_step', 'steps_with_score', 'consensus_filtering_algo_label', 'verifier_identified_first_incorrect_step_solution']\n"
     ]
    }
   ],
   "source": [
    "# load all JSONL files in the directory\n",
    "import os\n",
    "import json\n",
    "\n",
    "# TODO: Edit the MC last file path - then just Restart and Run All\n",
    "dir_path = \"/mnt/fast10/brandon/mmr_rollout_data/prm_training_data/debug/mc0.0\"\n",
    "\n",
    "first_jsonl = next((f for f in os.listdir(dir_path) if f.endswith(\".jsonl\")), None)\n",
    "if first_jsonl:\n",
    "    with open(os.path.join(dir_path, first_jsonl), \"r\") as f:\n",
    "        first_line = f.readline()\n",
    "        if first_line:\n",
    "            columns = list(json.loads(first_line).keys())\n",
    "            print(json.loads(first_line))\n",
    "        else:\n",
    "            columns = []\n",
    "else:\n",
    "    columns = []\n",
    "\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "701e5d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking schema consistency...\n",
      "✓ All files have consistent schema\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import json\n",
    "import os\n",
    "\n",
    "# First pass: Check schema consistency across all files\n",
    "print(\"Checking schema consistency...\")\n",
    "file_schemas = {}\n",
    "jsonl_files = [f for f in os.listdir(dir_path) if f.endswith(\".jsonl\")]\n",
    "\n",
    "for file in jsonl_files:\n",
    "    with open(os.path.join(dir_path, file), \"r\") as f:\n",
    "        first_line = f.readline()\n",
    "        if first_line:\n",
    "            schema = set(json.loads(first_line).keys())\n",
    "            file_schemas[file] = schema\n",
    "\n",
    "# Check if all schemas are identical\n",
    "reference_schema = next(iter(file_schemas.values()))\n",
    "inconsistent_files = []\n",
    "for file, schema in file_schemas.items():\n",
    "    if schema != reference_schema:\n",
    "        inconsistent_files.append((file, schema))\n",
    "\n",
    "if inconsistent_files:\n",
    "    print(\"WARNING: Schema inconsistencies found!\")\n",
    "    for file, schema in inconsistent_files:\n",
    "        print(f\"  {file}: {schema}\")\n",
    "        print(f\"    Missing: {reference_schema - schema}\")\n",
    "        print(f\"    Extra: {schema - reference_schema}\")\n",
    "else:\n",
    "    print(\"✓ All files have consistent schema\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f3c5960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mc_score: mc0.0\n"
     ]
    }
   ],
   "source": [
    "mc_score = dir_path.split(\"/\")[-1]\n",
    "print(f\"mc_score: {mc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f21d6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 1 files...\n",
      "Processing vqav2_final_mc_rollouts_with_all_models_verification_merged_prm_training_data_mc0.0.jsonl...\n",
      "  Lines processed: 8138\n",
      "\n",
      "Writing flattened data to /mnt/fast10/brandon/mmr_rollout_data/prm_training_data/debug/mc0.0/final_single_prm_training_data_mc0.0_v2.jsonl...\n",
      "✓ Flattened 8138 total records to /mnt/fast10/brandon/mmr_rollout_data/prm_training_data/debug/mc0.0/final_single_prm_training_data_mc0.0_v2.jsonl\n",
      "\n",
      "============================================================\n",
      "STATISTICS BY FILE\n",
      "============================================================\n",
      "\n",
      "vqav2_final_mc_rollouts_with_all_models_verification_merged_prm_training_data_mc0.0.jsonl:\n",
      "  Total records: 8138\n",
      "  First incorrect step sections:\n",
      "    Reasoning: 1014 (40.9% of incorrect samples)\n",
      "    Visual Elements: 1464 (59.1% of incorrect samples)\n",
      "  Consensus filtering labels:\n",
      "    o4-mini_correct_and_MC_agrees: 4650\n",
      "    o4-mini_correct_and_MC_disagrees: 1010\n",
      "    o4-mini_incorrect_and_MC_agrees_and_disagrees: 2478\n",
      "  Training samples breakdown:\n",
      "    Used for training: 7128 (4650 correct + 2478 incorrect)\n",
      "    Not used for training: 1010 (o4-mini_correct_and_MC_disagrees)\n",
      "    Training split: 65.2% correct, 34.8% incorrect\n",
      "\n",
      "============================================================\n",
      "OVERALL STATISTICS\n",
      "============================================================\n",
      "Total records across all files: 8138\n",
      "Overall first incorrect step sections:\n",
      "  Reasoning: 1014 (40.9% of incorrect samples)\n",
      "  Visual Elements: 1464 (59.1% of incorrect samples)\n",
      "Overall consensus filtering labels:\n",
      "  o4-mini_correct_and_MC_agrees: 4650\n",
      "  o4-mini_correct_and_MC_disagrees: 1010\n",
      "  o4-mini_incorrect_and_MC_agrees_and_disagrees: 2478\n",
      "Overall training samples breakdown:\n",
      "  Used for training: 7128 (4650 correct + 2478 incorrect)\n",
      "  Not used for training: 1010 (o4-mini_correct_and_MC_disagrees)\n",
      "  Training split: 65.2% correct, 34.8% incorrect\n"
     ]
    }
   ],
   "source": [
    "# Statistics collection\n",
    "file_stats = {}\n",
    "all_data = []\n",
    "\n",
    "print(f\"\\nProcessing {len(jsonl_files)} files...\")\n",
    "\n",
    "for file in jsonl_files:\n",
    "    print(f\"Processing {file}...\")\n",
    "    \n",
    "    # Initialize stats for this file\n",
    "    first_incorrect_step_sections = Counter()\n",
    "    consensus_filtering_labels = Counter()\n",
    "    line_count = 0\n",
    "    \n",
    "    with open(os.path.join(dir_path, file), \"r\") as f:\n",
    "        for line in f:\n",
    "            item = json.loads(line)\n",
    "            all_data.append(item)\n",
    "            line_count += 1\n",
    "            \n",
    "            # Collect first_incorrect_step section distribution\n",
    "            if \"first_incorrect_step\" in item and item[\"first_incorrect_step\"] is not None:\n",
    "                if isinstance(item[\"first_incorrect_step\"], (list, tuple)) and len(item[\"first_incorrect_step\"]) >= 1:\n",
    "                    section_name = item[\"first_incorrect_step\"][0]\n",
    "                    first_incorrect_step_sections[section_name] += 1\n",
    "            \n",
    "            # Collect consensus_filtering_algo_label distribution\n",
    "            if \"consensus_filtering_algo_label\" in item and item[\"consensus_filtering_algo_label\"] is not None:\n",
    "                consensus_filtering_labels[item[\"consensus_filtering_algo_label\"]] += 1\n",
    "    \n",
    "    # Store stats for this file\n",
    "    file_stats[file] = {\n",
    "        \"line_count\": line_count,\n",
    "        \"first_incorrect_step_sections\": dict(first_incorrect_step_sections),\n",
    "        \"consensus_filtering_labels\": dict(consensus_filtering_labels)\n",
    "    }\n",
    "    \n",
    "    print(f\"  Lines processed: {line_count}\")\n",
    "\n",
    "# TODO: CHANGE FILE NAME PATH!!!\n",
    "output_file = os.path.join(dir_path, f\"final_single_prm_training_data_{mc_score}_v2.jsonl\")\n",
    "print(f\"\\nWriting flattened data to {output_file}...\")\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    for item in all_data:\n",
    "        f.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "print(f\"✓ Flattened {len(all_data)} total records to {output_file}\")\n",
    "\n",
    "# Print statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STATISTICS BY FILE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for file, stats in file_stats.items():\n",
    "    print(f\"\\n{file}:\")\n",
    "    print(f\"  Total records: {stats['line_count']}\")\n",
    "    \n",
    "    # Get key counts for percentage calculations\n",
    "    incorrect_count = stats['consensus_filtering_labels'].get('o4-mini_incorrect_and_MC_agrees_and_disagrees', 0)\n",
    "    correct_count = stats['consensus_filtering_labels'].get('o4-mini_correct_and_MC_agrees', 0)\n",
    "    unused_count = stats['consensus_filtering_labels'].get('o4-mini_correct_and_MC_disagrees', 0)\n",
    "    \n",
    "    reasoning_count = stats['first_incorrect_step_sections'].get('Reasoning', 0)\n",
    "    visual_count = stats['first_incorrect_step_sections'].get('Visual Elements', 0)\n",
    "    \n",
    "    print(f\"  First incorrect step sections:\")\n",
    "    for section, count in sorted(stats['first_incorrect_step_sections'].items()):\n",
    "        if incorrect_count > 0:\n",
    "            pct = (count / incorrect_count) * 100\n",
    "            print(f\"    {section}: {count} ({pct:.1f}% of incorrect samples)\")\n",
    "        else:\n",
    "            print(f\"    {section}: {count} (no incorrect samples)\")\n",
    "    \n",
    "    print(f\"  Consensus filtering labels:\")\n",
    "    for label, count in sorted(stats['consensus_filtering_labels'].items()):\n",
    "        print(f\"    {label}: {count}\")\n",
    "    \n",
    "    # Training sample breakdown\n",
    "    training_total = correct_count + incorrect_count\n",
    "    print(f\"  Training samples breakdown:\")\n",
    "    print(f\"    Used for training: {training_total} ({correct_count} correct + {incorrect_count} incorrect)\")\n",
    "    print(f\"    Not used for training: {unused_count} (o4-mini_correct_and_MC_disagrees)\")\n",
    "    \n",
    "    if training_total > 0:\n",
    "        correct_pct = (correct_count / training_total) * 100\n",
    "        incorrect_pct = (incorrect_count / training_total) * 100\n",
    "        print(f\"    Training split: {correct_pct:.1f}% correct, {incorrect_pct:.1f}% incorrect\")\n",
    "    else:\n",
    "        print(f\"    Training split: No training samples\")\n",
    "\n",
    "# Overall statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OVERALL STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "all_sections = Counter()\n",
    "all_labels = Counter()\n",
    "\n",
    "for stats in file_stats.values():\n",
    "    for section, count in stats['first_incorrect_step_sections'].items():\n",
    "        all_sections[section] += count\n",
    "    for label, count in stats['consensus_filtering_labels'].items():\n",
    "        all_labels[label] += count\n",
    "\n",
    "print(f\"Total records across all files: {len(all_data)}\")\n",
    "\n",
    "# Overall key counts for percentage calculations\n",
    "overall_incorrect_count = all_labels.get('o4-mini_incorrect_and_MC_agrees_and_disagrees', 0)\n",
    "overall_correct_count = all_labels.get('o4-mini_correct_and_MC_agrees', 0)\n",
    "overall_unused_count = all_labels.get('o4-mini_correct_and_MC_disagrees', 0)\n",
    "\n",
    "print(f\"Overall first incorrect step sections:\")\n",
    "for section, count in sorted(all_sections.items()):\n",
    "    if overall_incorrect_count > 0:\n",
    "        pct = (count / overall_incorrect_count) * 100\n",
    "        print(f\"  {section}: {count} ({pct:.1f}% of incorrect samples)\")\n",
    "    else:\n",
    "        print(f\"  {section}: {count} (no incorrect samples)\")\n",
    "\n",
    "print(f\"Overall consensus filtering labels:\")\n",
    "for label, count in sorted(all_labels.items()):\n",
    "    print(f\"  {label}: {count}\")\n",
    "\n",
    "# Overall training sample breakdown\n",
    "overall_training_total = overall_correct_count + overall_incorrect_count\n",
    "print(f\"Overall training samples breakdown:\")\n",
    "print(f\"  Used for training: {overall_training_total} ({overall_correct_count} correct + {overall_incorrect_count} incorrect)\")\n",
    "print(f\"  Not used for training: {overall_unused_count} (o4-mini_correct_and_MC_disagrees)\")\n",
    "\n",
    "if overall_training_total > 0:\n",
    "    overall_correct_pct = (overall_correct_count / overall_training_total) * 100\n",
    "    overall_incorrect_pct = (overall_incorrect_count / overall_training_total) * 100\n",
    "    print(f\"  Training split: {overall_correct_pct:.1f}% correct, {overall_incorrect_pct:.1f}% incorrect\")\n",
    "else:\n",
    "    print(f\"  Training split: No training samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bccd43cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            messages  \\\n",
      "0  [{'role': 'system', 'content': [{'type': 'text...   \n",
      "1  [{'role': 'system', 'content': [{'type': 'text...   \n",
      "2  [{'role': 'system', 'content': [{'type': 'text...   \n",
      "3  [{'role': 'system', 'content': [{'type': 'text...   \n",
      "4  [{'role': 'system', 'content': [{'type': 'text...   \n",
      "\n",
      "                                              images  \\\n",
      "0  [s3://arf-share/arf-ob1-mm-reasoning/training_...   \n",
      "1  [s3://arf-share/arf-ob1-mm-reasoning/training_...   \n",
      "2  [s3://arf-share/arf-ob1-mm-reasoning/training_...   \n",
      "3  [s3://arf-share/arf-ob1-mm-reasoning/training_...   \n",
      "4  [s3://arf-share/arf-ob1-mm-reasoning/training_...   \n",
      "\n",
      "                                     id  \n",
      "0  00205c45-6ef8-456c-9409-caee64c59695  \n",
      "1  0028c172-433c-45e0-85eb-0d037e11c28d  \n",
      "2  002b3294-1dde-4830-8526-79cfa8158ccd  \n",
      "3  0033324c-528f-4fce-8e58-40aa33710574  \n",
      "4  003fdba9-9908-4676-801d-b69df5a27483  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dir_path = f\"/mnt/fast10/brandon/mmr_rollout_data/prm_training_data/train/{mc_score}/vqav2_final_mc_rollouts_with_all_models_verification_merged_prm_training_data_final_trl_format_{mc_score}.jsonl\"\n",
    "\n",
    "with open(dir_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "records = [json.loads(line) for line in lines if line.strip()]\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4e7ce42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://arf-share/arf-ob1-mm-reasoning/training_data_images/VQAv2/subset_images/COCO_train2014_000000240080.jpg'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0][\"images\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85f4409e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'user',\n",
       " 'content': [{'type': 'text',\n",
       "   'text': '<image>\\n### Question:\\nWhat year was this picture taken? Answer the question using a single word or phrase.\\n\\n### Solution Process:\\n[Visual Elements]\\n<step_1>\\nObserving several brown stuffed teddy bears, some with white paws, hanging close together, likely as display items.\\n</step_1>',\n",
       "   'index': None}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0][\"messages\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dd74b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/fast10/brandon/mmr_rollout_data/training_data_images/AI2D/subset_images/706.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "cwd_abs_path = os.path.abspath(os.getcwd())\n",
    "test_path = \"s3://arf-share/arf-ob1-mm-reasoning/training_data_images/AI2D/subset_images/706.png\"\n",
    "test_path = test_path.replace(\"s3://arf-share/arf-ob1-mm-reasoning/\", cwd_abs_path + \"/\")\n",
    "print(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e4ff84",
   "metadata": {},
   "source": [
    "# Run this part for merging the \"train\" TRL messages array directory\n",
    "- above runs merges for \"debug\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "076083ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_score = \"mc0.01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7df7930e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['messages', 'images', 'id']\n"
     ]
    }
   ],
   "source": [
    "# load all JSONL files in the directory\n",
    "import os\n",
    "import json\n",
    "\n",
    "dir_path = f\"/mnt/fast10/brandon/mmr_rollout_data/prm_training_data/train/{mc_score}\"\n",
    "\n",
    "first_jsonl = next((f for f in os.listdir(dir_path) if f.endswith(\".jsonl\")), None)\n",
    "if first_jsonl:\n",
    "    with open(os.path.join(dir_path, first_jsonl), \"r\") as f:\n",
    "        first_line = f.readline()\n",
    "        if first_line:\n",
    "            columns = list(json.loads(first_line).keys())\n",
    "        else:\n",
    "            columns = []\n",
    "else:\n",
    "    columns = []\n",
    "\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aaa1364b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking schema consistency...\n",
      "✓ All files have consistent schema\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import json\n",
    "import os\n",
    "\n",
    "# First pass: Check schema consistency across all files\n",
    "print(\"Checking schema consistency...\")\n",
    "file_schemas = {}\n",
    "jsonl_files = [f for f in os.listdir(dir_path) if f.endswith(\".jsonl\")]\n",
    "\n",
    "for file in jsonl_files:\n",
    "    with open(os.path.join(dir_path, file), \"r\") as f:\n",
    "        first_line = f.readline()\n",
    "        if first_line:\n",
    "            schema = set(json.loads(first_line).keys())\n",
    "            file_schemas[file] = schema\n",
    "\n",
    "# Check if all schemas are identical\n",
    "reference_schema = next(iter(file_schemas.values()))\n",
    "inconsistent_files = []\n",
    "for file, schema in file_schemas.items():\n",
    "    if schema != reference_schema:\n",
    "        inconsistent_files.append((file, schema))\n",
    "\n",
    "if inconsistent_files:\n",
    "    print(\"WARNING: Schema inconsistencies found!\")\n",
    "    for file, schema in inconsistent_files:\n",
    "        print(f\"  {file}: {schema}\")\n",
    "        print(f\"    Missing: {reference_schema - schema}\")\n",
    "        print(f\"    Extra: {schema - reference_schema}\")\n",
    "else:\n",
    "    print(\"✓ All files have consistent schema\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17b95a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing InfoVQA_final_mc_rollouts_with_all_models_verification_merged_prm_training_data_final_trl_format_mc0.01.jsonl...\n",
      "  Lines processed: 21750\n",
      "Processing AI2D_final_mc_rollouts_with_all_models_verification_merged_prm_training_data_final_trl_format_mc0.01.jsonl...\n",
      "  Lines processed: 20971\n",
      "Processing RAVEN_final_mc_rollouts_with_all_models_verification_merged_prm_training_data_final_trl_format_mc0.01.jsonl...\n",
      "  Lines processed: 198505\n",
      "Processing vqav2_final_mc_rollouts_with_all_models_verification_merged_prm_training_data_final_trl_format_mc0.01.jsonl...\n",
      "  Lines processed: 7128\n",
      "Processing dvqa_final_mc_rollouts_with_all_models_verification_merged_prm_training_data_final_trl_format_mc0.01.jsonl...\n",
      "  Lines processed: 16175\n",
      "Processing CLEVR_final_mc_rollouts_with_all_models_verification_merged_prm_training_data_final_trl_format_mc0.01.jsonl...\n",
      "  Lines processed: 25477\n",
      "\n",
      "Writing flattened data to /mnt/fast10/brandon/mmr_rollout_data/prm_training_data/train/mc0.01/final_flattened_trl_format_prm_training_data_500k_mc0.01_v2.jsonl...\n",
      "✓ Flattened 290006 total records to /mnt/fast10/brandon/mmr_rollout_data/prm_training_data/train/mc0.01/final_flattened_trl_format_prm_training_data_500k_mc0.01_v2.jsonl\n"
     ]
    }
   ],
   "source": [
    "all_data = []\n",
    "\n",
    "for file in jsonl_files:\n",
    "    print(f\"Processing {file}...\")\n",
    "    \n",
    "    line_count = 0\n",
    "    \n",
    "    with open(os.path.join(dir_path, file), \"r\") as f:\n",
    "        for line in f:\n",
    "            item = json.loads(line)\n",
    "            all_data.append(item)\n",
    "            line_count += 1\n",
    "    print(f\"  Lines processed: {line_count}\")\n",
    "\n",
    "# TODO: To change to respective version!\n",
    "output_file = os.path.join(dir_path, f\"final_flattened_trl_format_prm_training_data_500k_{mc_score}_v2.jsonl\")\n",
    "print(f\"\\nWriting flattened data to {output_file}...\")\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    for item in all_data:\n",
    "        f.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "print(f\"✓ Flattened {len(all_data)} total records to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a02f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push flattened JSONL path to S3 path\n",
    "# !aws s3 sync ./s3_upload_prm_training_data/prm_training_data_full_v1 s3://arf-share/arf-ob1-mm-reasoning/prm_training_data_full_v1/ --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e464e3",
   "metadata": {},
   "source": [
    "✓ Flattened 281334 total records to /mnt/fast10/brandon/mmr_rollout_data/prm_training_data/train/mc0.8/final_flattened_trl_format_prm_training_data_500k_mc0.8_v1.jsonl\n",
    "\n",
    "✓ Flattened 284787 total records to /mnt/fast10/brandon/mmr_rollout_data/prm_training_data/train/mc0.5/final_flattened_trl_format_prm_training_data_500k_mc0.5_v1.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42becd0a",
   "metadata": {},
   "source": [
    "✓ Flattened 290006 total records to /mnt/fast10/brandon/mmr_rollout_data/prm_training_data/train/mc0.0/final_flattened_trl_format_prm_training_data_500k_mc0.0_v2.jsonl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmr_processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
