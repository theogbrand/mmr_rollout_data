{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ace7f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'image_url', 'conversations', 'first_incorrect_step', 'steps_with_score', 'consensus_filtering_algo_label', 'verifier_identified_first_incorrect_step_solution']\n"
     ]
    }
   ],
   "source": [
    "# load all JSONL files in the directory\n",
    "import os\n",
    "import json\n",
    "\n",
    "dir_path = \"/mnt/fast10/brandon/mmr_rollout_data/prm_training_data/debug\"\n",
    "\n",
    "first_jsonl = next((f for f in os.listdir(dir_path) if f.endswith(\".jsonl\")), None)\n",
    "if first_jsonl:\n",
    "    with open(os.path.join(dir_path, first_jsonl), \"r\") as f:\n",
    "        first_line = f.readline()\n",
    "        if first_line:\n",
    "            columns = list(json.loads(first_line).keys())\n",
    "        else:\n",
    "            columns = []\n",
    "else:\n",
    "    columns = []\n",
    "\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "701e5d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking schema consistency...\n",
      "✓ All files have consistent schema\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import json\n",
    "import os\n",
    "\n",
    "# First pass: Check schema consistency across all files\n",
    "print(\"Checking schema consistency...\")\n",
    "file_schemas = {}\n",
    "jsonl_files = [f for f in os.listdir(dir_path) if f.endswith(\".jsonl\")]\n",
    "\n",
    "for file in jsonl_files:\n",
    "    with open(os.path.join(dir_path, file), \"r\") as f:\n",
    "        first_line = f.readline()\n",
    "        if first_line:\n",
    "            schema = set(json.loads(first_line).keys())\n",
    "            file_schemas[file] = schema\n",
    "\n",
    "# Check if all schemas are identical\n",
    "reference_schema = next(iter(file_schemas.values()))\n",
    "inconsistent_files = []\n",
    "for file, schema in file_schemas.items():\n",
    "    if schema != reference_schema:\n",
    "        inconsistent_files.append((file, schema))\n",
    "\n",
    "if inconsistent_files:\n",
    "    print(\"WARNING: Schema inconsistencies found!\")\n",
    "    for file, schema in inconsistent_files:\n",
    "        print(f\"  {file}: {schema}\")\n",
    "        print(f\"    Missing: {reference_schema - schema}\")\n",
    "        print(f\"    Extra: {schema - reference_schema}\")\n",
    "else:\n",
    "    print(\"✓ All files have consistent schema\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f21d6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 6 files...\n",
      "Processing dvqa_final_mc_rollouts_with_all_models_verification_merged_prm_training_data_mc0.8.jsonl...\n",
      "  Lines processed: 16663\n",
      "Processing AI2D_final_mc_rollouts_with_all_models_verification_merged_prm_training_data_mc0.8.jsonl...\n",
      "  Lines processed: 22399\n",
      "Processing RAVEN_final_mc_rollouts_with_all_models_verification_merged_prm_training_data_mc0.8.jsonl...\n",
      "  Lines processed: 203115\n",
      "Processing InfoVQA_final_mc_rollouts_with_all_models_verification_merged_prm_training_data_mc0.8.jsonl...\n",
      "  Lines processed: 25518\n",
      "Processing vqav2_final_mc_rollouts_with_all_models_verification_merged_prm_training_data_mc0.8.jsonl...\n",
      "  Lines processed: 8138\n",
      "Processing CLEVR_final_mc_rollouts_with_all_models_verification_merged_prm_training_data_mc0.8.jsonl...\n",
      "  Lines processed: 27326\n",
      "\n",
      "Writing flattened data to /mnt/fast10/brandon/mmr_rollout_data/prm_training_data/debug/final_single_prm_training_data_500k_mc0.8_v1.jsonl...\n",
      "✓ Flattened 303159 total records to /mnt/fast10/brandon/mmr_rollout_data/prm_training_data/debug/final_single_prm_training_data_500k_mc0.8_v1.jsonl\n",
      "\n",
      "============================================================\n",
      "STATISTICS BY FILE\n",
      "============================================================\n",
      "\n",
      "dvqa_final_mc_rollouts_with_all_models_verification_merged_prm_training_data_mc0.8.jsonl:\n",
      "  Total records: 16663\n",
      "  First incorrect step sections:\n",
      "    Reasoning: 1251 (29.6% of incorrect samples)\n",
      "    Visual Elements: 2982 (70.4% of incorrect samples)\n",
      "  Consensus filtering labels:\n",
      "    o4-mini_correct_and_MC_agrees: 11268\n",
      "    o4-mini_correct_and_MC_disagrees: 1162\n",
      "    o4-mini_incorrect_and_MC_agrees_and_disagrees: 4233\n",
      "  Training samples breakdown:\n",
      "    Used for training: 15501 (11268 correct + 4233 incorrect)\n",
      "    Not used for training: 1162 (o4-mini_correct_and_MC_disagrees)\n",
      "    Training split: 72.7% correct, 27.3% incorrect\n",
      "\n",
      "AI2D_final_mc_rollouts_with_all_models_verification_merged_prm_training_data_mc0.8.jsonl:\n",
      "  Total records: 22399\n",
      "  First incorrect step sections:\n",
      "    Reasoning: 1280 (19.4% of incorrect samples)\n",
      "    Visual Elements: 5334 (80.6% of incorrect samples)\n",
      "  Consensus filtering labels:\n",
      "    o4-mini_correct_and_MC_agrees: 11869\n",
      "    o4-mini_correct_and_MC_disagrees: 3916\n",
      "    o4-mini_incorrect_and_MC_agrees_and_disagrees: 6614\n",
      "  Training samples breakdown:\n",
      "    Used for training: 18483 (11869 correct + 6614 incorrect)\n",
      "    Not used for training: 3916 (o4-mini_correct_and_MC_disagrees)\n",
      "    Training split: 64.2% correct, 35.8% incorrect\n",
      "\n",
      "RAVEN_final_mc_rollouts_with_all_models_verification_merged_prm_training_data_mc0.8.jsonl:\n",
      "  Total records: 203115\n",
      "  First incorrect step sections:\n",
      "    Reasoning: 26752 (13.6% of incorrect samples)\n",
      "    Visual Elements: 170276 (86.4% of incorrect samples)\n",
      "  Consensus filtering labels:\n",
      "    o4-mini_correct_and_MC_agrees: 306\n",
      "    o4-mini_correct_and_MC_disagrees: 5781\n",
      "    o4-mini_incorrect_and_MC_agrees_and_disagrees: 197028\n",
      "  Training samples breakdown:\n",
      "    Used for training: 197334 (306 correct + 197028 incorrect)\n",
      "    Not used for training: 5781 (o4-mini_correct_and_MC_disagrees)\n",
      "    Training split: 0.2% correct, 99.8% incorrect\n",
      "\n",
      "InfoVQA_final_mc_rollouts_with_all_models_verification_merged_prm_training_data_mc0.8.jsonl:\n",
      "  Total records: 25518\n",
      "  First incorrect step sections:\n",
      "    Reasoning: 709 (18.5% of incorrect samples)\n",
      "    Visual Elements: 3119 (81.5% of incorrect samples)\n",
      "  Consensus filtering labels:\n",
      "    o4-mini_correct_and_MC_agrees: 15883\n",
      "    o4-mini_correct_and_MC_disagrees: 5807\n",
      "    o4-mini_incorrect_and_MC_agrees_and_disagrees: 3828\n",
      "  Training samples breakdown:\n",
      "    Used for training: 19711 (15883 correct + 3828 incorrect)\n",
      "    Not used for training: 5807 (o4-mini_correct_and_MC_disagrees)\n",
      "    Training split: 80.6% correct, 19.4% incorrect\n",
      "\n",
      "vqav2_final_mc_rollouts_with_all_models_verification_merged_prm_training_data_mc0.8.jsonl:\n",
      "  Total records: 8138\n",
      "  First incorrect step sections:\n",
      "    Reasoning: 1014 (40.9% of incorrect samples)\n",
      "    Visual Elements: 1464 (59.1% of incorrect samples)\n",
      "  Consensus filtering labels:\n",
      "    o4-mini_correct_and_MC_agrees: 4340\n",
      "    o4-mini_correct_and_MC_disagrees: 1320\n",
      "    o4-mini_incorrect_and_MC_agrees_and_disagrees: 2478\n",
      "  Training samples breakdown:\n",
      "    Used for training: 6818 (4340 correct + 2478 incorrect)\n",
      "    Not used for training: 1320 (o4-mini_correct_and_MC_disagrees)\n",
      "    Training split: 63.7% correct, 36.3% incorrect\n",
      "\n",
      "CLEVR_final_mc_rollouts_with_all_models_verification_merged_prm_training_data_mc0.8.jsonl:\n",
      "  Total records: 27326\n",
      "  First incorrect step sections:\n",
      "    Reasoning: 379 (3.7% of incorrect samples)\n",
      "    Visual Elements: 9755 (96.3% of incorrect samples)\n",
      "  Consensus filtering labels:\n",
      "    o4-mini_correct_and_MC_agrees: 13353\n",
      "    o4-mini_correct_and_MC_disagrees: 3839\n",
      "    o4-mini_incorrect_and_MC_agrees_and_disagrees: 10134\n",
      "  Training samples breakdown:\n",
      "    Used for training: 23487 (13353 correct + 10134 incorrect)\n",
      "    Not used for training: 3839 (o4-mini_correct_and_MC_disagrees)\n",
      "    Training split: 56.9% correct, 43.1% incorrect\n",
      "\n",
      "============================================================\n",
      "OVERALL STATISTICS\n",
      "============================================================\n",
      "Total records across all files: 303159\n",
      "Overall first incorrect step sections:\n",
      "  Reasoning: 31385 (14.0% of incorrect samples)\n",
      "  Visual Elements: 192930 (86.0% of incorrect samples)\n",
      "Overall consensus filtering labels:\n",
      "  o4-mini_correct_and_MC_agrees: 57019\n",
      "  o4-mini_correct_and_MC_disagrees: 21825\n",
      "  o4-mini_incorrect_and_MC_agrees_and_disagrees: 224315\n",
      "Overall training samples breakdown:\n",
      "  Used for training: 281334 (57019 correct + 224315 incorrect)\n",
      "  Not used for training: 21825 (o4-mini_correct_and_MC_disagrees)\n",
      "  Training split: 20.3% correct, 79.7% incorrect\n"
     ]
    }
   ],
   "source": [
    "# Statistics collection\n",
    "file_stats = {}\n",
    "all_data = []\n",
    "\n",
    "print(f\"\\nProcessing {len(jsonl_files)} files...\")\n",
    "\n",
    "for file in jsonl_files:\n",
    "    print(f\"Processing {file}...\")\n",
    "    \n",
    "    # Initialize stats for this file\n",
    "    first_incorrect_step_sections = Counter()\n",
    "    consensus_filtering_labels = Counter()\n",
    "    line_count = 0\n",
    "    \n",
    "    with open(os.path.join(dir_path, file), \"r\") as f:\n",
    "        for line in f:\n",
    "            item = json.loads(line)\n",
    "            all_data.append(item)\n",
    "            line_count += 1\n",
    "            \n",
    "            # Collect first_incorrect_step section distribution\n",
    "            if \"first_incorrect_step\" in item and item[\"first_incorrect_step\"] is not None:\n",
    "                if isinstance(item[\"first_incorrect_step\"], (list, tuple)) and len(item[\"first_incorrect_step\"]) >= 1:\n",
    "                    section_name = item[\"first_incorrect_step\"][0]\n",
    "                    first_incorrect_step_sections[section_name] += 1\n",
    "            \n",
    "            # Collect consensus_filtering_algo_label distribution\n",
    "            if \"consensus_filtering_algo_label\" in item and item[\"consensus_filtering_algo_label\"] is not None:\n",
    "                consensus_filtering_labels[item[\"consensus_filtering_algo_label\"]] += 1\n",
    "    \n",
    "    # Store stats for this file\n",
    "    file_stats[file] = {\n",
    "        \"line_count\": line_count,\n",
    "        \"first_incorrect_step_sections\": dict(first_incorrect_step_sections),\n",
    "        \"consensus_filtering_labels\": dict(consensus_filtering_labels)\n",
    "    }\n",
    "    \n",
    "    print(f\"  Lines processed: {line_count}\")\n",
    "\n",
    "# Write flattened data to single file\n",
    "output_file = os.path.join(dir_path, \"final_single_prm_training_data_500k_mc0.8_v1.jsonl\")\n",
    "print(f\"\\nWriting flattened data to {output_file}...\")\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    for item in all_data:\n",
    "        f.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "print(f\"✓ Flattened {len(all_data)} total records to {output_file}\")\n",
    "\n",
    "# Print statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STATISTICS BY FILE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for file, stats in file_stats.items():\n",
    "    print(f\"\\n{file}:\")\n",
    "    print(f\"  Total records: {stats['line_count']}\")\n",
    "    \n",
    "    # Get key counts for percentage calculations\n",
    "    incorrect_count = stats['consensus_filtering_labels'].get('o4-mini_incorrect_and_MC_agrees_and_disagrees', 0)\n",
    "    correct_count = stats['consensus_filtering_labels'].get('o4-mini_correct_and_MC_agrees', 0)\n",
    "    unused_count = stats['consensus_filtering_labels'].get('o4-mini_correct_and_MC_disagrees', 0)\n",
    "    \n",
    "    reasoning_count = stats['first_incorrect_step_sections'].get('Reasoning', 0)\n",
    "    visual_count = stats['first_incorrect_step_sections'].get('Visual Elements', 0)\n",
    "    \n",
    "    print(f\"  First incorrect step sections:\")\n",
    "    for section, count in sorted(stats['first_incorrect_step_sections'].items()):\n",
    "        if incorrect_count > 0:\n",
    "            pct = (count / incorrect_count) * 100\n",
    "            print(f\"    {section}: {count} ({pct:.1f}% of incorrect samples)\")\n",
    "        else:\n",
    "            print(f\"    {section}: {count} (no incorrect samples)\")\n",
    "    \n",
    "    print(f\"  Consensus filtering labels:\")\n",
    "    for label, count in sorted(stats['consensus_filtering_labels'].items()):\n",
    "        print(f\"    {label}: {count}\")\n",
    "    \n",
    "    # Training sample breakdown\n",
    "    training_total = correct_count + incorrect_count\n",
    "    print(f\"  Training samples breakdown:\")\n",
    "    print(f\"    Used for training: {training_total} ({correct_count} correct + {incorrect_count} incorrect)\")\n",
    "    print(f\"    Not used for training: {unused_count} (o4-mini_correct_and_MC_disagrees)\")\n",
    "    \n",
    "    if training_total > 0:\n",
    "        correct_pct = (correct_count / training_total) * 100\n",
    "        incorrect_pct = (incorrect_count / training_total) * 100\n",
    "        print(f\"    Training split: {correct_pct:.1f}% correct, {incorrect_pct:.1f}% incorrect\")\n",
    "    else:\n",
    "        print(f\"    Training split: No training samples\")\n",
    "\n",
    "# Overall statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OVERALL STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "all_sections = Counter()\n",
    "all_labels = Counter()\n",
    "\n",
    "for stats in file_stats.values():\n",
    "    for section, count in stats['first_incorrect_step_sections'].items():\n",
    "        all_sections[section] += count\n",
    "    for label, count in stats['consensus_filtering_labels'].items():\n",
    "        all_labels[label] += count\n",
    "\n",
    "print(f\"Total records across all files: {len(all_data)}\")\n",
    "\n",
    "# Overall key counts for percentage calculations\n",
    "overall_incorrect_count = all_labels.get('o4-mini_incorrect_and_MC_agrees_and_disagrees', 0)\n",
    "overall_correct_count = all_labels.get('o4-mini_correct_and_MC_agrees', 0)\n",
    "overall_unused_count = all_labels.get('o4-mini_correct_and_MC_disagrees', 0)\n",
    "\n",
    "print(f\"Overall first incorrect step sections:\")\n",
    "for section, count in sorted(all_sections.items()):\n",
    "    if overall_incorrect_count > 0:\n",
    "        pct = (count / overall_incorrect_count) * 100\n",
    "        print(f\"  {section}: {count} ({pct:.1f}% of incorrect samples)\")\n",
    "    else:\n",
    "        print(f\"  {section}: {count} (no incorrect samples)\")\n",
    "\n",
    "print(f\"Overall consensus filtering labels:\")\n",
    "for label, count in sorted(all_labels.items()):\n",
    "    print(f\"  {label}: {count}\")\n",
    "\n",
    "# Overall training sample breakdown\n",
    "overall_training_total = overall_correct_count + overall_incorrect_count\n",
    "print(f\"Overall training samples breakdown:\")\n",
    "print(f\"  Used for training: {overall_training_total} ({overall_correct_count} correct + {overall_incorrect_count} incorrect)\")\n",
    "print(f\"  Not used for training: {overall_unused_count} (o4-mini_correct_and_MC_disagrees)\")\n",
    "\n",
    "if overall_training_total > 0:\n",
    "    overall_correct_pct = (overall_correct_count / overall_training_total) * 100\n",
    "    overall_incorrect_pct = (overall_incorrect_count / overall_training_total) * 100\n",
    "    print(f\"  Training split: {overall_correct_pct:.1f}% correct, {overall_incorrect_pct:.1f}% incorrect\")\n",
    "else:\n",
    "    print(f\"  Training split: No training samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bccd43cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            messages  \\\n",
      "0  [{'role': 'system', 'content': [{'type': 'text...   \n",
      "1  [{'role': 'system', 'content': [{'type': 'text...   \n",
      "2  [{'role': 'system', 'content': [{'type': 'text...   \n",
      "3  [{'role': 'system', 'content': [{'type': 'text...   \n",
      "4  [{'role': 'system', 'content': [{'type': 'text...   \n",
      "\n",
      "                                              images  \\\n",
      "0  [s3://arf-share/arf-ob1-mm-reasoning/training_...   \n",
      "1  [s3://arf-share/arf-ob1-mm-reasoning/training_...   \n",
      "2  [s3://arf-share/arf-ob1-mm-reasoning/training_...   \n",
      "3  [s3://arf-share/arf-ob1-mm-reasoning/training_...   \n",
      "4  [s3://arf-share/arf-ob1-mm-reasoning/training_...   \n",
      "\n",
      "                                     id  \n",
      "0  0004b572-06fb-48a6-bc3e-2363fdfcc600  \n",
      "1  000bb035-cc5a-44b5-9517-88dcbbce240d  \n",
      "2  000c4850-5b73-4302-9835-60e07771762d  \n",
      "3  0011c413-b7e6-4f61-ad8f-0f5942ffc31e  \n",
      "4  0018cebc-5f77-417e-9185-8abeb076f868  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dir_path = \"/mnt/fast10/brandon/mmr_rollout_data/prm_training_data/train/CLEVR_final_mc_rollouts_with_all_models_verification_merged_prm_training_data_final_trl_format_mc0.8.jsonl\"\n",
    "\n",
    "with open(dir_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "records = [json.loads(line) for line in lines if line.strip()]\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4e7ce42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://arf-share/arf-ob1-mm-reasoning/training_data_images/CLEVR-MATH/subset_images/CLEVR_train_067191.png'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0][\"images\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3dd74b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/fast10/brandon/mmr_rollout_data/training_data_images/AI2D/subset_images/706.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "cwd_abs_path = os.path.abspath(os.getcwd())\n",
    "test_path = \"s3://arf-share/arf-ob1-mm-reasoning/training_data_images/AI2D/subset_images/706.png\"\n",
    "test_path = test_path.replace(\"s3://arf-share/arf-ob1-mm-reasoning/\", cwd_abs_path + \"/\")\n",
    "print(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7df7930e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['messages', 'images', 'id']\n"
     ]
    }
   ],
   "source": [
    "# load all JSONL files in the directory\n",
    "import os\n",
    "import json\n",
    "\n",
    "dir_path = \"/mnt/fast10/brandon/mmr_rollout_data/prm_training_data/train\"\n",
    "\n",
    "first_jsonl = next((f for f in os.listdir(dir_path) if f.endswith(\".jsonl\")), None)\n",
    "if first_jsonl:\n",
    "    with open(os.path.join(dir_path, first_jsonl), \"r\") as f:\n",
    "        first_line = f.readline()\n",
    "        if first_line:\n",
    "            columns = list(json.loads(first_line).keys())\n",
    "        else:\n",
    "            columns = []\n",
    "else:\n",
    "    columns = []\n",
    "\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaa1364b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking schema consistency...\n",
      "✓ All files have consistent schema\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import json\n",
    "import os\n",
    "\n",
    "# First pass: Check schema consistency across all files\n",
    "print(\"Checking schema consistency...\")\n",
    "file_schemas = {}\n",
    "jsonl_files = [f for f in os.listdir(dir_path) if f.endswith(\".jsonl\")]\n",
    "\n",
    "for file in jsonl_files:\n",
    "    with open(os.path.join(dir_path, file), \"r\") as f:\n",
    "        first_line = f.readline()\n",
    "        if first_line:\n",
    "            schema = set(json.loads(first_line).keys())\n",
    "            file_schemas[file] = schema\n",
    "\n",
    "# Check if all schemas are identical\n",
    "reference_schema = next(iter(file_schemas.values()))\n",
    "inconsistent_files = []\n",
    "for file, schema in file_schemas.items():\n",
    "    if schema != reference_schema:\n",
    "        inconsistent_files.append((file, schema))\n",
    "\n",
    "if inconsistent_files:\n",
    "    print(\"WARNING: Schema inconsistencies found!\")\n",
    "    for file, schema in inconsistent_files:\n",
    "        print(f\"  {file}: {schema}\")\n",
    "        print(f\"    Missing: {reference_schema - schema}\")\n",
    "        print(f\"    Extra: {schema - reference_schema}\")\n",
    "else:\n",
    "    print(\"✓ All files have consistent schema\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17b95a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing InfoVQA_final_mc_rollouts_with_all_models_verification_merged_prm_training_data_final_trl_format_mc0.8.jsonl...\n",
      "  Lines processed: 19711\n",
      "Processing vqav2_final_mc_rollouts_with_all_models_verification_merged_prm_training_data_final_trl_format_mc0.8.jsonl...\n",
      "  Lines processed: 6818\n",
      "Processing CLEVR_final_mc_rollouts_with_all_models_verification_merged_prm_training_data_final_trl_format_mc0.8.jsonl...\n",
      "  Lines processed: 23487\n",
      "Processing AI2D_final_mc_rollouts_with_all_models_verification_merged_prm_training_data_final_trl_format_mc0.8.jsonl...\n",
      "  Lines processed: 18483\n",
      "Processing RAVEN_final_mc_rollouts_with_all_models_verification_merged_prm_training_data_final_trl_format_mc0.8.jsonl...\n",
      "  Lines processed: 197334\n",
      "Processing dvqa_final_mc_rollouts_with_all_models_verification_merged_prm_training_data_final_trl_format_mc0.8.jsonl...\n",
      "  Lines processed: 15501\n",
      "\n",
      "Writing flattened data to /mnt/fast10/brandon/mmr_rollout_data/prm_training_data/train/final_flattened_trl_format_prm_training_data_500k_mc0.8_v1.jsonl...\n",
      "✓ Flattened 281334 total records to /mnt/fast10/brandon/mmr_rollout_data/prm_training_data/train/final_flattened_trl_format_prm_training_data_500k_mc0.8_v1.jsonl\n"
     ]
    }
   ],
   "source": [
    "all_data = []\n",
    "\n",
    "for file in jsonl_files:\n",
    "    print(f\"Processing {file}...\")\n",
    "    \n",
    "    line_count = 0\n",
    "    \n",
    "    with open(os.path.join(dir_path, file), \"r\") as f:\n",
    "        for line in f:\n",
    "            item = json.loads(line)\n",
    "            all_data.append(item)\n",
    "            line_count += 1\n",
    "    print(f\"  Lines processed: {line_count}\")\n",
    "\n",
    "output_file = os.path.join(dir_path, \"final_flattened_trl_format_prm_training_data_500k_mc0.8_v1.jsonl\")\n",
    "print(f\"\\nWriting flattened data to {output_file}...\")\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    for item in all_data:\n",
    "        f.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "print(f\"✓ Flattened {len(all_data)} total records to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92a02f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: prm_training_data_full_v0/final_flattened_trl_format_prm_training_data_500k_mc0.8_v1.jsonl to s3://arf-share/arf-ob1-mm-reasoning/prm_training_data_full_v0/final_flattened_trl_format_prm_training_data_500k_mc0.8_v1.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Push flattened JSONL path to S3 path\n",
    "!aws s3 cp ./prm_training_data_full_v0 s3://arf-share/arf-ob1-mm-reasoning/prm_training_data_full_v0/ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e464e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmr_processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
